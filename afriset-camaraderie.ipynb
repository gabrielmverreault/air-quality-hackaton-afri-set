{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_file = 'data/Example Data - JSON/sensors-africa.json'\n",
    "#input_data_file = 'data/Example Data - JSON/airly.json'\n",
    "#input_data_file = 'data/Example Data - JSON/sensors-africa.json'\n",
    "#input_data_file = 'data/Example Data - CSVs/TTTR/clarity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import what we need and set up our AWS session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import importlib\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    region_name=os.getenv(\"AWS_REGION\"), profile_name=os.getenv(\"AWS_PROFILE\")\n",
    ")\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',    \n",
    "    region_name=os.environ.get(\"AWS_REGION\", None))\n",
    "\n",
    "sns_client = session.client('sns')\n",
    "s3 = session.client('s3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(csv_file):\n",
    "\n",
    "    df = pd.read_csv(csv_file, nrows=0)\n",
    "    num_expected_cols = len(df.columns)\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Identify numeric and string columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns \n",
    "    string_cols = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    # String columns - fill NaN with empty string \n",
    "    df[string_cols] = df[string_cols].fillna('')  \n",
    "\n",
    "    # Numeric cols - fill NaN with Pandas NaN\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(pd.NA)\n",
    "\n",
    "    # Trim or drop rows with extra columns\n",
    "    df = df.iloc[:, :num_expected_cols]  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_file(input_data_file):\n",
    "  ext = input_data_file.split('.')[-1]\n",
    "  \n",
    "  if ext == 'json':\n",
    "    data = json.load(open(input_data_file))\n",
    "    threshold = 50000\n",
    "    if len(str(data)) > threshold:\n",
    "      sample_data = str(data)[:threshold]\n",
    "    else:\n",
    "      sample_data = data\n",
    "\n",
    "  elif ext == 'csv':\n",
    "      data = preprocess_csv(input_data_file)\n",
    "      sample_data = data\n",
    "\n",
    "  return sample_data, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_code(text):\n",
    "  # Extract code from markdown codeblock   \n",
    "  pattern = r'```python(.*?)\\n```'\n",
    "  match = re.search(pattern, text, re.DOTALL)\n",
    "  if match:\n",
    "    return match.group(1)\n",
    "  return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(input_data_file):\n",
    "  ext = input_data_file.split('.')[-1]\n",
    "  if ext == 'json':\n",
    "    data = json.load(open(input_data_file))\n",
    "    threshold = 50000\n",
    "    if len(str(data)) > threshold:\n",
    "      sample_data = str(data)[:threshold]\n",
    "    else:\n",
    "      sample_data = data\n",
    "    output = llm(p1_prompt_template.format(input=sample_data))\n",
    "    convert_code = (get_final_code(output))\n",
    "    exec(convert_code,globals())\n",
    "    df = convert_to_df(data)\n",
    "  elif ext == 'csv':\n",
    "      df = preprocess_csv(input_data_file)\n",
    "      convert_code = ''\n",
    "  return df, convert_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_type(llm_output):\n",
    "    match = re.search(r'<tableType>(\\w+)</tableType>', llm_output)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch_LLM_invocations(file_name, is_existing):\n",
    "    if not is_existing:\n",
    "        human_in_the_loop(file_name)\n",
    "    else:\n",
    "        pass # call some python function later to output SQL tables\n",
    "def human_in_the_loop(file_name):\n",
    "    message = \"New data format is detected! Please check the file: \" + file_name\n",
    "    msg_body = json.dumps(message)\n",
    "    sns_client.publish(\n",
    "                TopicArn=sns_topic_arn,\n",
    "                Message=json.dumps({'default': msg_body}),\n",
    "                MessageStructure='json')\n",
    "    print(\"\\nSNS published message: \\n\" + str(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_template = \"\"\"Given the following input file containing air quality data from sensors:\n",
    "    <input> {input} </input> \n",
    "    Provide some python code to convert the data into a pandas dataframe. It should be a function that takes in one input, the input data, as a `dict`.\n",
    "    `def convert_to_df(input_data):`\n",
    "    The function should return a panda dataframe.\n",
    "    <requirements>\n",
    "    Make sure to import all libraries required.\n",
    "    Flatten the json as required.\n",
    "    The timestamp should always be stored as a timestamp. The code must handle conversion. Be mindful of string vs integer. Use a <scratchpad> to Think step by step and insure that the function will work properly when the input data is fed to it.\n",
    "    </requirements>\n",
    "    \n",
    "    OUTPUT: Wrap your final code in the <FinalCode> XML tag and make sure it is formatted as a python code block in Markdown\n",
    "    EXAMPLE: <FinalCode>```python\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_to_df(input_data):\n",
    "        ...\n",
    "``` \n",
    "</FinalCode>\n",
    "    \"\"\"\n",
    "\n",
    "p1_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=p1_template\n",
    ")\n",
    "\n",
    "template_pivot = \"\"\"Type1 table format:\n",
    "- Each row contains a timestamp\n",
    "- Each column represents a measurement taken at that time\n",
    "- Each sensor reading has its own column \n",
    "- Type1 example: \n",
    "<Type1TableExample>\n",
    "City,State,Country,Latitude,Longitude,pollution_ts,aqius,mainus,aqicn,maincn,wether_ts,pr,hu,ws,wd,ic\n",
    "Accra,Greater Accra,Ghana,-0.186964,5.603717,2023-11-25T23:00:00.000Z,74,p2,33,p2,26,1011,82,4.12,272,04n\n",
    "</Type1TableExample>\n",
    "\n",
    "Type2 table format \n",
    "- Each row contains a timestamp\n",
    "- One column contains the tag name or value type. This column will not contain the measurements, but instead a string of what the measurement is collecting.\n",
    "- One column contains the measurement value for that tag. This column will not contain the tag name or value type, but simply the value.\n",
    "- This table type will generally have only a few columns (3-9)\n",
    "- Type2 example: \n",
    "<Type2TableExample>\n",
    "timestamp;location;sensor;software_version;value_type;value\n",
    "2023-11-30 20:37:40.316811+00:00;3615;4829;NRZ-2020-129;P2;14.25\n",
    "2023-11-30 20:37:40.316811+00:00;3615;4829;NRZ-2020-129;P1;16.25\n",
    "2023-11-30 20:37:40.316811+00:00;3615;4829;NRZ-2020-129;P0;10.0\n",
    "</Type2TableExample>\n",
    "\n",
    "Given the following table:\n",
    "<table>\n",
    "{rawtable}\n",
    "</table>\n",
    "\n",
    "\n",
    "Analyze the input table and respond with:\n",
    "\n",
    "1. The identified table type (Type1 or Type2). Write the answer in a <tableType> XML tag. Think step by step in <scratchpad> to properly identify the type.\n",
    "\n",
    "2. If the table is Type2:\n",
    "   - Provide a Python function to transform the table to Type1 format. \n",
    "   - The Python functin should be called convert_to_type1 and take in a single input, the input dataframe\n",
    "   - Use markdown to write the function in a python codeblock\n",
    "\n",
    "If already Type1, state no transformation needed.\n",
    "\n",
    "<example>\n",
    "table:\n",
    "timestamp;location;sensor;software_version;value_type;value\n",
    "2023-11-30 20:37:40.316811+00:00;3615;4829;NRZ-2020-129;P2;14.25\n",
    "2023-11-30 20:37:40.316811+00:00;3615;4829;NRZ-2020-129;P1;16.25\n",
    "2023-11-30 20:37:40.316811+00:00;3615;4829;NRZ-2020-129;P0;10.0\n",
    "2023-11-30 20:37:08.424916+00:00;3615;4829;NRZ-2020-129;P2;12.0\n",
    "2023-11-30 20:37:08.424916+00:00;3615;4829;NRZ-2020-129;P1;12.0\n",
    "2023-11-30 20:37:08.424916+00:00;3615;4829;NRZ-2020-129;P0;9.0\n",
    "2023-11-30 20:36:36.545464+00:00;3615;4829;NRZ-2020-129;P2;13.4\n",
    "2023-11-30 20:36:36.545464+00:00;3615;4829;NRZ-2020-129;P1;16.0\n",
    "2023-11-30 20:36:36.545464+00:00;3615;4829;NRZ-2020-129;P0;8.0\n",
    "2023-11-30 20:36:04.634028+00:00;3615;4829;NRZ-2020-129;P2;10.5\n",
    "\n",
    "<scratchpad>This table has the following key characteristics:\n",
    "A timestamp column\n",
    "Columns indicating metadata like location, sensor, software version\n",
    "Columns for value_type and value\n",
    "Each row contains a timestamp, metadata about the reading, the type of value, and the actual value. Different value types are captured in different rows for the same timestamp.\n",
    "This matches the description of a Type 2 table format:\n",
    "Timestamp column\n",
    "One column for tag name/value type\n",
    "One column for the measurement value\n",
    "Multiple value types captured per timestamp across rows\n",
    "Therefore, I would classify this as a Type 2 table format. Therefore I need to write a function to transform it to Type1. To do so, I need to look at the values in value_type and pivot them so they become columns. </scratchpad>\n",
    "<tableType>Type2</tableType>\n",
    "\n",
    "2: Here is the python code to transform the table to Type1 format:\n",
    "```python\n",
    "function:\n",
    "import pandas as pd  \n",
    "\n",
    "def convert_to_type1(df):\n",
    "    df_pivoted = df.pivot(index=['timestamp', 'location', 'sensor', 'software_version'], \n",
    "                          columns='value_type',\n",
    "                          values='value')\n",
    "    \n",
    "    df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "    return df_pivoted\n",
    "```\n",
    "</example>\n",
    "\n",
    "Table type analysis and transformation function (if applicable):\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_pivot = PromptTemplate(\n",
    "    input_variables=[\"rawtable\"],\n",
    "    template=template_pivot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "templateTransform = \"\"\"Given this dataframe:\n",
    "{input_df}\n",
    "Perform the following operations to create a python function called `transform_df`:\n",
    "<tasks>\n",
    "For each column, use the column name and the values, to determine what the column likely contains. Provide a description. Store those desciptions in a <description> XML tag for every column in the dataframe. This does not belong in the function. It is to help you think.\n",
    "\n",
    "<context>\n",
    "For context, this is data from air quality sensors, so some common items are:\n",
    "temperature (in Celsius), humidity, relative humidity, PM1 are extremely fine particulates with a diameter of fewer than 1 microns. PM2.5 (also known as fine particles) have a diameter of less than 2.5 microns. PM10 means the particles have a diameter less than 10 microns, or 100 times smaller than a millimeter.\n",
    "in some dataframes, there will only be a location id (numerical), sometimes, a city. Store the most relevant location, if available, ALWAYS as a string.\n",
    "<context>\n",
    "The output file name for all rows will be: {input_filename}\n",
    "When creating the new dataframe, make sure to properly define the datatype. If not certain, string is OK.\n",
    "THEN, write a python function to convert it to a dataframe of this format:\n",
    "<output_structure>\n",
    "{output_structure}\n",
    "</output_structure>\n",
    "Do your best to match the input dataframe to the target. If there are no values for a column of the output_structure, write None\n",
    "\n",
    "Output your code in python markdown, in <FinalCode> XML tag \n",
    "</tasks>\n",
    "EXAMPLE:\n",
    "<FinalCode> ```python\n",
    "import pandas as pd\n",
    "\n",
    "def transform_df(df):\n",
    "    \n",
    "    output_df = pd.DataFrame(columns=['deviceId', 'timestamp', 'locationId', 'geo_lat', 'geo_lon', 'pm1', 'pm10', 'pm25', 'temperature', 'pressure', 'humidity', 'sourcefile'])\n",
    "    \n",
    "    output_df['deviceId'] = df['sn']\n",
    "    output_df['timestamp'] = df['timestamp']\n",
    "    output_df['locationId'] = None\n",
    "    output_df['geo_lat'] = df['lat']\n",
    "    output_df['geo_lon'] = df['lon'] \n",
    "    output_df['pm1'] = df['pm1']\n",
    "    output_df['pm10'] = df['pm10']\n",
    "    output_df['pm25'] = df['pm25']\n",
    "    output_df['temperature'] = df['temp'] \n",
    "    output_df['pressure'] = None \n",
    "    output_df['humidity'] = df['rh']\n",
    "    output_df['sourcefile'] = df['url']\n",
    "    \n",
    "    return output_df\n",
    "```\n",
    "</FinalCode>\n",
    "\n",
    "GO!\n",
    "\"\"\"\n",
    "output_structure = \"\"\"\n",
    "deviceId | timestamp | locationId | geo_lat | geo_lon | pm1 | pm10 | pm25 | temperature | pressure | humidity | sourcefile \n",
    "\n",
    "Make sure you store the data in the dataframe with the following datatype:\n",
    "<datatype>\n",
    "deviceId          object\n",
    "timestamp    datetime64[ns]\n",
    "locationId        object\n",
    "geo_lat           object   \n",
    "geo_lon           object\n",
    "pm1               float64\n",
    "pm10              float64\n",
    "pm25              float64\n",
    "temperature       float64\n",
    "pressure          float64\n",
    "humidity          float64\n",
    "sourcefile        object\n",
    "</datatype>\n",
    "\n",
    "\"\"\"\n",
    "prompt_template2 = PromptTemplate(\n",
    "    input_variables=[\"input_df\", \"output_structure\", \"input_filename\"],\n",
    "    template=templateTransform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the new data file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_filename = re.sub(r'[\\\\/:*?\"<>|.]+', '_', os.path.splitext(input_data_file)[0])[:255].strip(' .')\n",
    "fileformat = re.sub(r'[\\- ]+', '_',cleaned_filename) #version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bedrock(model_id=\"anthropic.claude-v2:1\", client=bedrock_runtime, model_kwargs={\"temperature\":0,\"max_tokens_to_sample\": 8000, \"top_k\": 250, \"top_p\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data format exists, will retrieve existing functions\n"
     ]
    }
   ],
   "source": [
    "# decide to call existing python code or human_in_the_loop\n",
    "# Create a topic for sns to publish and sqs to subscribe\n",
    "sns_topic = sns_client.create_topic(Name=\"notify-operator\")\n",
    "sns_topic_arn = sns_topic['TopicArn']\n",
    "\n",
    "if os.path.isdir(os.path.join(\"functions\", fileformat)):\n",
    "    print(sns_topic_arn)\n",
    "    branch_LLM_invocations(fileformat, True) #sns notif\n",
    "else:\n",
    "    print(\"data format exists, will retrieve existing functions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>sensor</th>\n",
       "      <th>software_version</th>\n",
       "      <th>value</th>\n",
       "      <th>value_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-30 20:37:40.316811+00:00</td>\n",
       "      <td>63136960</td>\n",
       "      <td>3615</td>\n",
       "      <td>4829</td>\n",
       "      <td>NRZ-2020-129</td>\n",
       "      <td>14.25</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-30 20:37:40.316811+00:00</td>\n",
       "      <td>63136960</td>\n",
       "      <td>3615</td>\n",
       "      <td>4829</td>\n",
       "      <td>NRZ-2020-129</td>\n",
       "      <td>16.25</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-30 20:37:40.316811+00:00</td>\n",
       "      <td>63136960</td>\n",
       "      <td>3615</td>\n",
       "      <td>4829</td>\n",
       "      <td>NRZ-2020-129</td>\n",
       "      <td>10.00</td>\n",
       "      <td>P0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp        id  location  sensor  \\\n",
       "0 2023-11-30 20:37:40.316811+00:00  63136960      3615    4829   \n",
       "1 2023-11-30 20:37:40.316811+00:00  63136960      3615    4829   \n",
       "2 2023-11-30 20:37:40.316811+00:00  63136960      3615    4829   \n",
       "\n",
       "  software_version  value value_type  \n",
       "0     NRZ-2020-129  14.25         P2  \n",
       "1     NRZ-2020-129  16.25         P1  \n",
       "2     NRZ-2020-129  10.00         P0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logic to create the initial df\n",
    "df, convert_code = create_df(input_data_file)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot row / columns as needed if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>value_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>sensor</th>\n",
       "      <th>software_version</th>\n",
       "      <th>P0</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-30 20:32:42.592915+00:00</td>\n",
       "      <td>63136769</td>\n",
       "      <td>3615</td>\n",
       "      <td>4829</td>\n",
       "      <td>NRZ-2020-129</td>\n",
       "      <td>10.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-30 20:33:14.522366+00:00</td>\n",
       "      <td>63136784</td>\n",
       "      <td>3615</td>\n",
       "      <td>4829</td>\n",
       "      <td>NRZ-2020-129</td>\n",
       "      <td>9.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-30 20:33:46.429630+00:00</td>\n",
       "      <td>63136804</td>\n",
       "      <td>3615</td>\n",
       "      <td>4829</td>\n",
       "      <td>NRZ-2020-129</td>\n",
       "      <td>10.00</td>\n",
       "      <td>17.50</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "value_type                        timestamp        id  location  sensor  \\\n",
       "0          2023-11-30 20:32:42.592915+00:00  63136769      3615    4829   \n",
       "1          2023-11-30 20:33:14.522366+00:00  63136784      3615    4829   \n",
       "2          2023-11-30 20:33:46.429630+00:00  63136804      3615    4829   \n",
       "\n",
       "value_type software_version     P0     P1     P2  \n",
       "0              NRZ-2020-129  10.00  18.00  14.00  \n",
       "1              NRZ-2020-129   9.00  18.00  15.00  \n",
       "2              NRZ-2020-129  10.00  17.50  15.75  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawtable = df.head(10).to_csv(sep=';', index = False)\n",
    "output_transformation = llm(prompt_template_pivot.format(rawtable=rawtable))\n",
    "table_type = get_table_type(output_transformation)\n",
    "if table_type == 'Type1':\n",
    "    dft1 = df\n",
    "    code_pivot = ''\n",
    "else: \n",
    "    if table_type == 'Type2':\n",
    "        code_pivot = get_final_code(output_transformation) \n",
    "        exec(code_pivot,globals())\n",
    "        dft1 = convert_to_type1(df)\n",
    "    else:\n",
    "        raise ValueError('Invalid table type')\n",
    "    \n",
    "dft1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get to the final table with standardized column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>locationId</th>\n",
       "      <th>geo_lat</th>\n",
       "      <th>geo_lon</th>\n",
       "      <th>pm1</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>sourcefile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63136769</td>\n",
       "      <td>2023-11-30 20:32:42.592915+00:00</td>\n",
       "      <td>3615</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sensors-africa.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63136784</td>\n",
       "      <td>2023-11-30 20:33:14.522366+00:00</td>\n",
       "      <td>3615</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sensors-africa.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63136804</td>\n",
       "      <td>2023-11-30 20:33:46.429630+00:00</td>\n",
       "      <td>3615</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.00</td>\n",
       "      <td>17.50</td>\n",
       "      <td>15.75</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sensors-africa.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deviceId                        timestamp locationId geo_lat geo_lon  \\\n",
       "0  63136769 2023-11-30 20:32:42.592915+00:00       3615    None    None   \n",
       "1  63136784 2023-11-30 20:33:14.522366+00:00       3615    None    None   \n",
       "2  63136804 2023-11-30 20:33:46.429630+00:00       3615    None    None   \n",
       "\n",
       "     pm1   pm10   pm25 temperature pressure humidity           sourcefile  \n",
       "0  10.00  18.00  14.00        None     None     None  sensors-africa.json  \n",
       "1   9.00  18.00  15.00        None     None     None  sensors-africa.json  \n",
       "2  10.00  17.50  15.75        None     None     None  sensors-africa.json  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tf = llm(prompt_template2.format(input_df=dft1.head(10).to_csv(sep=';', index = False), output_structure=output_structure, input_filename=input_data_file))\n",
    "code_tf  = (get_final_code(output_tf))\n",
    "exec(code_tf, globals())\n",
    "df_tf = transform_df(dft1)\n",
    "df_tf.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "bucket_name = os.getenv('S3_BUCKET')\n",
    "\n",
    "# Save the dataframe to a file in S3\n",
    "s3.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=\"processed/transformed/csv/\" + cleaned_filename + \"_\" + timestamp + \".csv\",\n",
    "    Body=df_tf.to_csv(index=False));\n",
    "\n",
    "# Save the dataframe to a file in S3\n",
    "s3.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=\"processed/raw/csv/\" + cleaned_filename + \"_\" + timestamp + \".csv\",\n",
    "    Body=dft1.to_csv(index=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join(\"functions\", fileformat)\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "with open(os.path.join(folder, \"code_tf.py\"), \"w\") as f:\n",
    "    f.write(code_tf)\n",
    "    \n",
    "with open(os.path.join(folder, \"code_pivot.py\"), \"w\") as f:\n",
    "    f.write(code_pivot)\n",
    "    \n",
    "with open(os.path.join(folder, \"convert_code.py\"), \"w\") as f:\n",
    "    f.write(convert_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
